{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:red'>Quantitative Investing with Python</span>\n",
    "\n",
    "### Professor Juhani Linnainmaa\n",
    "\n",
    "Dartmouth College (George J. Records Professor of Investments) and Kepos Capital (Co-Director of Research)\n",
    "\n",
    "*First version:* January 26, 2024\n",
    "\n",
    "--- \n",
    "\n",
    "# **Topic 6:** Machine Learning in Quantitative Finance--Linear Models\n",
    "\n",
    "### Goal\n",
    "\n",
    "We want to create a model that predicts monthly stock returns with\n",
    "\n",
    "- Past monthly returns\n",
    "- Book-to-market ratio\n",
    "- Asset growth (investment) \n",
    "- Gross profitability \n",
    "\n",
    "The goal is to get these predictions and then see how well we would do by buying stocks with high predicted returns and selling those with low predicted returns\n",
    "\n",
    "\n",
    "### How\n",
    "\n",
    "- Work with 500 randomly selected stocks\n",
    "  - We use the same CRSP/Compustat database we constructed in Topic #4\n",
    "\n",
    "\n",
    "- We divide the sample into three parts: \n",
    "  1. training sample\n",
    "  2. validation sample, and \n",
    "  3. testing sample\n",
    "   \n",
    "   \n",
    "  In this topic we won't touch the testing sample\n",
    "  \n",
    "  \n",
    "- We **train** different models using the training sample\n",
    "  - We use the *validation* sample to compare different models\n",
    "  \n",
    "  \n",
    "- Once we are satisfied that we have made a reasonable choice, we will use the testing sample\n",
    "\n",
    "\n",
    "### Plan:\n",
    "\n",
    "1. Create the sample by selecting stocks that appear somewhere in the training + test samples we choose\n",
    "\n",
    "\n",
    "2. Define **target** variable (next month's return) and **features**\n",
    "\n",
    "\n",
    "3. Linear models:\n",
    "   - Linear regression\n",
    "   - Ridge regression\n",
    "     - **What is it?**\n",
    "     - Train the model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Constructing sample\n",
    "\n",
    "Construct a random sample of {number_of_stocks} starting from CRSP-Compustat file we created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "number_of_stocks = 500\n",
    "\n",
    "# sample dates\n",
    "first_train_date, last_train_date = '1963-06', '1990-12'\n",
    "first_validation_date, last_validation_date = '1991-01', '2000-12'\n",
    "first_test_date, last_test_date = '2001-01', '2010-12'\n",
    "\n",
    "# create random sample\n",
    "cs_crsp = pd.read_pickle('data/cs_crsp.pkl')\n",
    "\n",
    "train_dates = pd.period_range(first_train_date, last_train_date, freq='M')\n",
    "validation_dates = pd.period_range(first_validation_date, last_validation_date, freq='M')\n",
    "test_dates  = pd.period_range(first_test_date, last_test_date, freq='M')\n",
    "\n",
    "all_dates = train_dates.union(validation_dates).union(test_dates)\n",
    "\n",
    "# limit the sample to contain the dates determined above\n",
    "idx = pd.IndexSlice # for slicing a MultiIndex\n",
    "cs_crsp = cs_crsp.loc[idx[:, all_dates], :]\n",
    "\n",
    "# randomly select {number_of_stocks} that show up somewhere in the sample period\n",
    "permnos = pd.Series(cs_crsp.index.get_level_values(0).unique(), name='PERMNO')\n",
    "sample_permnos = permnos.sample(n=number_of_stocks, random_state=42).values\n",
    "\n",
    "cs_crsp = cs_crsp.loc[sample_permnos,:]\n",
    "\n",
    "# save \n",
    "cs_crsp.to_pickle('data/ml_crsp.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Determine the target variables and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Here is the raw data:\\n\\n', cs_crsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target variable\n",
    "\n",
    "Each stock's return the next month\n",
    "\n",
    "### Define features\n",
    "\n",
    "1-12: a stock's return in month t-k+1\n",
    "\n",
    "13: log-size\n",
    "\n",
    "14: log-book-to-market\n",
    "\n",
    "15: gross profitability\n",
    "\n",
    "\n",
    "**Note:** We often take 'logs' in linear models so that the variables have nicer distributions\n",
    "\n",
    "\n",
    "### Normalize variables by demeaning\n",
    "\n",
    "- We \"cross-sectionally demean\" both the target variable and the features so that it makes sense to estimate pooled regressions\n",
    "- A pooled regression refers to a sample that has both a time dimension and some cross-sectional dimension (multiple stocks each month in our case)\n",
    "- This does *not* introduce a lookahead bias\n",
    "- In terms of investing, this means that we are trying to model which stocks do poorly or well *relative* to other stocks\n",
    "  - Known as 'relative value' investing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "cs_crsp = pd.read_pickle('data/ml_crsp.pkl')\n",
    "\n",
    "# the TARGET variable is the return next month\n",
    "\n",
    "cs_crsp['retnm'] = cs_crsp.groupby(level='PERMNO')['ret'].shift(-1)\n",
    "\n",
    "# The FIRST set of features consist of monthly returns over the past year\n",
    "for lag in range(12):\n",
    "    cs_crsp['x0_retlag' + str(lag)] = cs_crsp.groupby(level='PERMNO')['ret'].shift(lag)\n",
    "    \n",
    "# The SECOND set of features are (a) log-size, (b) log-BE/ME, (c) log-asset growth, and (d) gross profitability\n",
    "\n",
    "# (1) log-size\n",
    "cs_crsp['x1_logme'] = np.log(cs_crsp['me'])\n",
    "\n",
    "# (2) log-book-to-market\n",
    "cs_crsp['beme'] = cs_crsp['be'] / cs_crsp['me']\n",
    "cs_crsp['x2_logbeme'] = np.log(cs_crsp['beme'])\n",
    "\n",
    "# (3) asset growth\n",
    "cs_crsp['at_lag12'] = cs_crsp.groupby(level='PERMNO')['at'].shift(12)\n",
    "cs_crsp['x3_log_asset_growth'] = np.log(cs_crsp['at'] / cs_crsp['at_lag12'])\n",
    "bad_data = (cs_crsp['at'] <= 0) | (cs_crsp['at_lag12'] <= 0) \n",
    "cs_crsp.loc[bad_data, 'x3_log_asset_growth'] = np.nan\n",
    "\n",
    "# (4) gross profitability\n",
    "cs_crsp['x4_gross_profitability'] = (cs_crsp['sale'] - cs_crsp['cogs']) / cs_crsp['at']\n",
    "bad_data = cs_crsp['at'] <= 0 \n",
    "cs_crsp.loc[bad_data, 'x4_gross_profitability'] = np.nan\n",
    "\n",
    "# Keep only the variables we need\n",
    "# This will give an error because we try to take logs of some negative numbers. This is fine because we want those to be missing.\n",
    "target_var = ['retnm']\n",
    "features = [c for c in cs_crsp.columns if c.startswith('x')]\n",
    "cs_crsp = cs_crsp[target_var + features]\n",
    "\n",
    "# Normalize variable by cross-sectionally demeaning\n",
    "\n",
    "cs_crsp = cs_crsp.sub(cs_crsp.groupby(level='date').mean(), level='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Estimate Linear Regression using Training Data\n",
    "\n",
    "- We first use statsmodels.api, similar to Topic #4, to estimate a linear regression using the **training data**\n",
    "- This package is good for its summary capabilities -- that is, when we want *to* interpret the model\n",
    "- We do this so that we can compare the results to what we know about stock returns from the academic literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the sample to contain all TRAINING data observations and drop all observations with any missing values\n",
    "train_data = cs_crsp.loc[idx[:, train_dates], :].dropna()\n",
    "\n",
    "y = train_data['retnm']\n",
    "X = train_data[features]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Specify the model\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the results:\n",
    "\n",
    "We see:\n",
    "\n",
    "- Short-term reversals\n",
    "- Momentum, with some of the variables statistically significant in isolation\n",
    "- Value, investment, and profitability effects\n",
    "\n",
    "\n",
    "Put differently, the estimates are consistent with what we know about stock returns from the academic literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Get predicted values from the model \n",
    "\n",
    "#### Questions:\n",
    "\n",
    "- Do they correlate with realized returns?\n",
    "- How well does a strategy that buys all stocks with predicted positive returns and sells those with predicted negative returns do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pred_retnm'] = results.fittedvalues\n",
    "\n",
    "print('Correlation:\\n')\n",
    "train_data[['retnm', 'pred_retnm']].corr().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable \"position\" that indicates which stocks we want to buy and which to sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['position'] = train_data['pred_retnm'].apply(lambda x: \"buys\" if x>0 else \"sells\" if x<0 else np.nan)\n",
    "portfolio_returns = train_data.reset_index(level='date').groupby(['date','position'])['retnm'].mean()\n",
    "portfolio_returns = portfolio_returns.unstack(level='position')\n",
    "strategy = portfolio_returns['buys'] - portfolio_returns['sells']\n",
    "strategy = strategy.shift(1) # undo timing, that is, the fact that we compute returns based on the return NEXT month\n",
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_returns(r=None, name=None, start_date='1962-05', end_date='2023-09'):\n",
    "    r = r.loc[start_date:end_date]\n",
    "    start_date, end_date = r.index.min(), r.index.max()\n",
    "    ir = np.sqrt(12) * r.mean() / r.std()\n",
    "    print(f'Analysis of a strategy: \"{name}\"')\n",
    "    print(f'Start: {start_date}, End: {end_date}')\n",
    "    print(f'Sharpe ratio: {ir:.2f}')\n",
    "    r.cumsum().plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_returns(r=strategy, name='Trade predictions of the linear regression in the training sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Is this a strategy we could have implemented in real time?\n",
    "\n",
    "- No, even if we knew the model we wanted to estimate (and the variables we wanted to use to predict returns), we fit the model using the same data\n",
    "- If the model fit to the noise, it will still look like we made money\n",
    "- We can use the **validation sample** to examine how good the model is\n",
    "  - That data is also noisy but the noise is something that the model didn't see when it was fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = cs_crsp.loc[idx[:, validation_dates], :].dropna()\n",
    "\n",
    "y = validation_data['retnm']\n",
    "X = validation_data[features]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# we can feed features from the validation sample to the estimated model using the \"predict\" method\n",
    "validation_data['pred_retnm'] = results.predict(X)\n",
    "\n",
    "print('Correlation:\\n')\n",
    "validation_data[['retnm', 'pred_retnm']].corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['position'] = validation_data['pred_retnm'].apply(lambda x: \"buys\" if x>0 else \"sells\" if x<0 else np.nan)\n",
    "portfolio_returns = validation_data.reset_index(level='date').groupby(['date','position'])['retnm'].mean()\n",
    "portfolio_returns = portfolio_returns.unstack(level='position')\n",
    "strategy = portfolio_returns['buys'] - portfolio_returns['sells']\n",
    "\n",
    "analyze_returns(r=strategy, name='Trade predictions of the linear regression in the training sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.2: Ridge regression \n",
    "\n",
    "- Ridge regression is a technique for preventing overfitting to data\n",
    "\n",
    "\n",
    "- When you estimate a linear regression, you're searching for best slopes (or coefficients) for the least squares line\n",
    "  - These slopes can be sensitive to outliers; those outliers 'pull' slopes towards them\n",
    "\n",
    "\n",
    "- A ridge regression is different from a linear regression in that there is a single penalty parameter that makes coefficient estimates less sensitive to the data\n",
    "  - You can think about the penalty parameter as being a \"budget\" for how large all the slopes can be together\n",
    "  - This penalty shrinks all slopes towards zero\n",
    "  \n",
    "  \n",
    "- The penalty parameter -- known as **L2 penalty** for its mathematical definition and often designated as 'alpha' -- is a **hyperparameter**\n",
    "  - We need to specify this parameter before we fit the model to the data\n",
    "  - How do we know how to set this parameter?\n",
    "  - Typical solution: \n",
    "    - Split the sample into fitting and validation samples \n",
    "    - Train models for many different choices of the penalty parameter using the training sample\n",
    "    - Pick the model that performs the best in the validation sample\n",
    "\n",
    "\n",
    "- In the code below I use cross validation to do this\n",
    "\n",
    "\n",
    "- Note: For technical reasons, we should always normalize features when we estimate a ridge regression\n",
    "  - The 'scales' of the variables should be comparable -- unless there is a really good reason to deviate from this principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the sample to contain all TRAINING data observations and drop all observations with any missing values\n",
    "train_data = cs_crsp.loc[idx[:, train_dates], :].dropna()\n",
    "\n",
    "y_train = train_data['retnm']\n",
    "X_train = train_data[features]\n",
    "\n",
    "# Scale the features to have mean zero and unit standard deviation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Define the RidgeCV model with 5-fold cross-validation\n",
    "# alphas is a numpy array of values for alpha (the regularization strength) that we want to test\n",
    "# np.logspace gives us a wide range of values\n",
    "model = RidgeCV(alphas=np.logspace(-6, 6, 50), cv=KFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the predicted values\n",
    "train_data['pred_retnm'] = model.predict(X_train_scaled)\n",
    "\n",
    "# Since you're using scikit-learn, there's no summary function like in statsmodels\n",
    "# But you can print out the alpha (regularization strength) that was chosen and the coefficients\n",
    "print(f'Chosen alpha from cross validation: {model.alpha_:,.2f}\\n')\n",
    "\n",
    "print('Coefficients')\n",
    "pd.Series(model.coef_, index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = cs_crsp.loc[idx[:, validation_dates], :].dropna()\n",
    "\n",
    "X_validation = validation_data[features]\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "\n",
    "# we can feed features from the validation sample to the estimated model using the \"predict\" method\n",
    "validation_data['pred_retnm'] = model.predict(X_validation_scaled)\n",
    "\n",
    "print('Correlation:\\n')\n",
    "validation_data[['retnm', 'pred_retnm']].corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['position'] = validation_data['pred_retnm'].apply(lambda x: \"buys\" if x>0 else \"sells\" if x<0 else np.nan)\n",
    "portfolio_returns = validation_data.reset_index(level='date').groupby(['date','position'])['retnm'].mean()\n",
    "portfolio_returns = portfolio_returns.unstack(level='position')\n",
    "strategy = portfolio_returns['buys'] - portfolio_returns['sells']\n",
    "\n",
    "analyze_returns(r=strategy, name='Ridge regression predictions in the validation sample')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
